{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/narozo/AppliedDeepLearningClass/blob/master/Untitled3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MbP8B_W8JADe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning\n",
        "\n",
        "We will use a pretrained image classification model from Keras. They are documented [here](https://keras.io/applications/)"
      ]
    },
    {
      "metadata": {
        "id": "NbPsRFiDF0U8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5526fbc6-89b9-4b07-d225-9ce153884ade"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 400\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# build the MobileNet network\n",
        "model = applications.MobileNet(include_top=False, weights='imagenet'                    # en este punto se trae el modelo\n",
        "                               , input_shape=(img_width, img_height, 3))\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "bottleneck_features_train = model.predict_generator(                                    # el bottleneck es un banco de imagenes creado\n",
        "    generator, nb_train_samples // batch_size)\n",
        "np.save('bottleneck_features_train.npy',\n",
        "        bottleneck_features_train)\n",
        "\n",
        "generator = datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "bottleneck_features_validation = model.predict_generator(\n",
        "    generator, nb_validation_samples // batch_size)\n",
        "np.save('bottleneck_features_validation.npy',\n",
        "        bottleneck_features_validation)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_128_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 3s 0us/step\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1RO_DAaaJU5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a0f10d0-1691-4aa2-93b1-2a4247f10ad1"
      },
      "cell_type": "code",
      "source": [
        "bottleneck_features_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 4, 4, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "wB4EwCerKHum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3360
        },
        "outputId": "a3790472-7c08-493c-f4c2-b40eba7e95bf"
      },
      "cell_type": "code",
      "source": [
        "model.summary()                                                                     # primer modelo (precargaddo)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_oIaT8ZKSFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1129
        },
        "outputId": "d65b446e-9e19-45dd-8e06-0e3952bd3a9c"
      },
      "cell_type": "code",
      "source": [
        "train_data = np.load('bottleneck_features_train.npy')\n",
        "train_labels = np.array(\n",
        "    [0] * int(nb_train_samples / 2) + [1] * int(nb_train_samples / 2))\n",
        "\n",
        "validation_data = np.load('bottleneck_features_validation.npy')\n",
        "validation_labels = np.array(\n",
        "    [0] * int(nb_validation_samples / 2) + [1] * int(nb_validation_samples / 2))\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "model_1.add(Dense(256, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_1.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(train_data, train_labels,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(validation_data, validation_labels))\n",
        "model_1.save_weights(top_model_weights_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2000 samples, validate on 400 samples\n",
            "Epoch 1/50\n",
            "2000/2000 [==============================] - 17s 9ms/step - loss: 7.9226 - acc: 0.4985 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 2/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "1840/2000 [==========================>...] - ETA: 1s - loss: 1.2751 - acc: 0.8973"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 1.2394 - acc: 0.8980 - val_loss: 0.5428 - val_acc: 0.9450\n",
            "Epoch 4/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6578 - acc: 0.9450 - val_loss: 0.6896 - val_acc: 0.9325\n",
            "Epoch 5/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5639 - acc: 0.9525 - val_loss: 0.4822 - val_acc: 0.9575\n",
            "Epoch 6/50\n",
            " 880/2000 [============>.................] - ETA: 8s - loss: 0.4098 - acc: 0.9614"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4396 - acc: 0.9615 - val_loss: 0.4290 - val_acc: 0.9675\n",
            "Epoch 7/50\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3922 - acc: 0.9720 - val_loss: 0.6131 - val_acc: 0.9475\n",
            "Epoch 8/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3645 - acc: 0.9700 - val_loss: 0.3721 - val_acc: 0.9700\n",
            "Epoch 9/50\n",
            " 720/2000 [=========>....................] - ETA: 10s - loss: 0.3101 - acc: 0.9736"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3501 - acc: 0.9730 - val_loss: 0.4308 - val_acc: 0.9650\n",
            "Epoch 10/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2966 - acc: 0.9750 - val_loss: 0.2579 - val_acc: 0.9725\n",
            "Epoch 11/50\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2850 - acc: 0.9780 - val_loss: 0.6207 - val_acc: 0.9450\n",
            "Epoch 12/50\n",
            " 640/2000 [========>.....................] - ETA: 10s - loss: 0.2377 - acc: 0.9812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2584 - acc: 0.9795 - val_loss: 0.8247 - val_acc: 0.9425\n",
            "Epoch 13/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2254 - acc: 0.9830 - val_loss: 0.4799 - val_acc: 0.9650\n",
            "Epoch 14/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2371 - acc: 0.9820 - val_loss: 0.6231 - val_acc: 0.9550\n",
            "Epoch 15/50\n",
            " 672/2000 [=========>....................] - ETA: 10s - loss: 0.3066 - acc: 0.9777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2720 - acc: 0.9800 - val_loss: 0.5799 - val_acc: 0.9600\n",
            "Epoch 16/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1900 - acc: 0.9855 - val_loss: 0.3351 - val_acc: 0.9700\n",
            "Epoch 17/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1614 - acc: 0.9875 - val_loss: 0.4557 - val_acc: 0.9650\n",
            "Epoch 18/50\n",
            " 688/2000 [=========>....................] - ETA: 10s - loss: 0.2337 - acc: 0.9840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1686 - acc: 0.9880 - val_loss: 0.4911 - val_acc: 0.9650\n",
            "Epoch 19/50\n",
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0987 - acc: 0.9930 - val_loss: 0.4202 - val_acc: 0.9625\n",
            "Epoch 20/50\n",
            "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1428 - acc: 0.9890 - val_loss: 0.4003 - val_acc: 0.9650\n",
            "Epoch 21/50\n",
            " 624/2000 [========>.....................] - ETA: 11s - loss: 0.0666 - acc: 0.9952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0815 - acc: 0.9940 - val_loss: 0.3856 - val_acc: 0.9700\n",
            "Epoch 22/50\n",
            "2000/2000 [==============================] - 12s 6ms/step - loss: 0.1591 - acc: 0.9870 - val_loss: 0.6005 - val_acc: 0.9575\n",
            "Epoch 23/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1345 - acc: 0.9895 - val_loss: 0.5856 - val_acc: 0.9525\n",
            "Epoch 24/50\n",
            " 672/2000 [=========>....................] - ETA: 10s - loss: 0.1080 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1171 - acc: 0.9915 - val_loss: 0.4074 - val_acc: 0.9675\n",
            "Epoch 25/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0989 - acc: 0.9930 - val_loss: 0.3981 - val_acc: 0.9725\n",
            "Epoch 26/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1215 - acc: 0.9910 - val_loss: 0.3995 - val_acc: 0.9675\n",
            "Epoch 27/50\n",
            " 656/2000 [========>.....................] - ETA: 10s - loss: 0.0243 - acc: 0.9985"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0677 - acc: 0.9950 - val_loss: 0.4562 - val_acc: 0.9625\n",
            "Epoch 28/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0522 - acc: 0.9965 - val_loss: 0.4368 - val_acc: 0.9675\n",
            "Epoch 29/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0732 - acc: 0.9945 - val_loss: 0.3680 - val_acc: 0.9725\n",
            "Epoch 30/50\n",
            " 704/2000 [=========>....................] - ETA: 9s - loss: 0.1375 - acc: 0.9872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0785 - acc: 0.9935 - val_loss: 0.4009 - val_acc: 0.9700\n",
            "Epoch 31/50\n",
            "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0475 - acc: 0.9970 - val_loss: 0.4444 - val_acc: 0.9650\n",
            "Epoch 32/50\n",
            "1904/2000 [===========================>..] - ETA: 0s - loss: 0.0450 - acc: 0.9963"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E_4IW53uK_Vy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}